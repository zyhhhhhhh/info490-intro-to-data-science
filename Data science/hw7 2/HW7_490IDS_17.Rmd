---
title: "hw7_490IDS_17"
author: '17'
date: "10/22/2016"
output: word_document
---

(a) Words with @ symbols in them, e.g., h@te or v|c0din
```{r}
print("^.*[[:punct:]].*$")
a = "ah@te12|b"
regexpr("^.*[[:punct:]].*$" ,a)
a = "v|c0dim"
regexpr("^.*[[:punct:]].*$" ,a)
```

(b) An IP address (Four sets of 1 to 3 digits separated by periods, e.g., 100.12.162.0)
```{r}
print("^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}$" )
a = "100.12.162.0"
regexpr("^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}$" ,a)
a = "100.12.162.0a"
regexpr("^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}$" ,a)
```

(c) An email address that ends with .com, .edu, .net, .org, or .gov
```{r}
print("^[^@]*@[^@]*[\\.com|\\.edu|\\.net|\\.org|\\.gov]$")
a = "ah@te12b.org"
regexpr("^[^@]*@[^@]*[\\.com|\\.edu|\\.net|\\.org|\\.gov]$" ,a)
```

Q. 2) (19 points) Carry out the following exercises on the State of the Union
speeches database (available in moodle).
(a) Use readLines() to read in the speeches (available as a text file in
moodle) where the return value is: character vector with one element/character
string per line in the file
```{r}
myText <- readLines("stateoftheunion1790-2012.txt")
```

(b) Use regular expressions to find ***
```{r}
stars= unlist(regmatches(myText, gregexpr("\\*\\*\\*", myText)))
```


(c) Use *** to identify the date of the speech.
```{r}
locations = grep("^\\*\\*\\*$", myText)
dates = myText[locations[]+4]
```


(d) Use regular expressions to extract the year.
```{r}
years = regexpr("\\<\\d\\d\\d\\d\\>",dates)
years_list = unlist(regmatches(dates, gregexpr("\\<\\d\\d\\d\\d\\>", dates)))
```


(e) Use regular expressions to extract the month.
```{r}
months = regexpr("^[[:upper:]][[:lower:]]*\\>",dates)
months_list = unlist(regmatches(dates, gregexpr("^[[:upper:]][[:lower:]]*\\>", dates)))
```

(f) Use *** to extract the name of the president State of the union
speeches.
```{r}
presidents = myText[locations[]+3]
```


(g) Use regular expressions and R to return the number of speeches in
the dataset, and the number of presidents that gave speeches.
```{r}
num_speech = length(presidents)
print("number of speeches")
num_speech
president_list = as.data.frame(table(presidents))
president_list = unlist(c(president_list["presidents"]))
num_president = length(president_list)
print("number of presidents")
num_president
```

(h) Chop the speeches up into a list there is one element for each speech.
Each element is a character vector. Check: does your number of list
elements match your answer above?
```{r}
speeches = c()
for (i in 1:(length(locations)-1)){
  a = c(unlist(myText[locations[i]:locations[i+1]-1], recursive = TRUE))
  a = paste(a, collapse = " ")
  speeches[i] =a
}
a = c(unlist(myText[locations[length(locations)]:(length(myText)-1)], recursive = TRUE))
a = paste(a, collapse = " ")
speeches[length(locations)] =a
length(speeches)
print("Yes, there's 222 elements.")
```

(i) Eliminate apostrophes, numbers, and the phrase: (Applause.)

```{r}
newspeeches = speeches
for (i in 1:length(newspeeches)){
  newspeeches[i] = gsub("\\<\\S+'\\S+\\>", "", newspeeches[i])
}

for (i in 1:length(newspeeches)){
  newspeeches[i] = gsub("[[:digit:]]", "", newspeeches[i])
}


for (i in 1:length(newspeeches)){
  newspeeches[i] = gsub("\\<.*Applause.*\\>", "", newspeeches[i])
}
```

(j) Make all the characters lower case.
```{r}
newspeeches <- lapply(newspeeches, FUN = tolower)
```


(k) Split the sentences up where there are blanks and punctuation to
create "words".
```{r}

words = c()
for (i in 1:length(newspeeches)){
  words = c(words,unlist(strsplit(as.character(newspeeches[i]), "[[:blank:]]|[[:punct:]]",perl = TRUE,useBytes = TRUE)))
}
print(length(words))
```


(l) Drop any empty words that resulted from this split.
```{r}
words = words[words != ""]
print(length(words))
```

(m) Create a word vector for each speech.
```{r}
words_vec = list()
for (i in 1:length(newspeeches)){
  a =unlist(strsplit(as.character(newspeeches[i]), "[[:blank:]]|[[:punct:]]",perl = TRUE,useBytes = TRUE))
  a = a[a!=""]
  a = as.vector(a)
  words_vec[[i]] = a
}


```

(n) Normalize the word vectors to get term frequencies.
```{r}
frequencies = words_vec
for (i in 1:length(frequencies)){
  a = as.vector(frequencies[[i]])
  l = length(a)
  b = table(a)
  for (j in 1:length(frequencies[[i]])){
    frequencies[[i]][j] = as.numeric(b[a[j]])/l
  }
}
```

(o) (5 points) Carry out some exploratory analysis of the data and term
frequencies. For example, find the number of sentences, extract the
long words, and the political party. Plot and interpret the term
frequencies. What are your observations?
```{r}
a = table(words_vec[[216]])
mean(a)
sd(a)
c = names(a)
d = as.numeric(sapply(c,nchar))
b = a[which(d>mean(d))]
b = b[b>mean(a)+0.2*sd(a)]
plot(b)
text(b, lab=row.names(b))

a = table(words_vec[[217]])
mean(a)
sd(a)
c = names(a)
d = as.numeric(sapply(c,nchar))
b = a[which(d>mean(d))]
b = b[b>mean(a)+0.2*sd(a)]
plot(b)
text(b, lab=row.names(b))

a = table(words_vec[[221]])
mean(a)
sd(a)
c = names(a)
d = as.numeric(sapply(c,nchar))
b = a[which(d>mean(d))]
b = b[b>mean(a)+0.2*sd(a)]
plot(b)
text(b, lab=row.names(b))

a = table(words_vec[[222]])
mean(a)
sd(a)
c = names(a)
d = as.numeric(sapply(c,nchar))
b = a[which(d>mean(d))]
b = b[b>mean(a)+0.2*sd(a)]
plot(b)
text(b, lab=row.names(b))
print("Above was 4 graphs on frequent words in the speech by J.W Bush and Obama. I filtered only long words and the frequency has to be large. The first two are by Bush; the latter 2 are by Obama. Despite from America and American, we can easily tell that there's a difference in their focus. J.W Bush has been using military, security and terrorists frequently. Obama has been using education, business, innovation, technology and companies more frequently.
      The reason could be Bush has a main focus on anti-terrorists. History also proved that this stat is correct, Bush vote for the war and Obama against it. When Bush was in duty, 9/11 happened. When Obama was in duty, he had to deal with the consequences of financial crisis, so his main focus will be on business, thus the word business appears more.")




```

